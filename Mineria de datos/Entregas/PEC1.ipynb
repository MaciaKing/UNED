{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breve resumen Teorico del problema\n",
    "El problema de la replicabilidad en la actualidad representa un desafío significativo, especialmente en el campo del machine learning, donde la variedad de modelos desarrollados es amplia y diversa. \n",
    "\n",
    "La existencia de múltiples modelos para resolver un mismo problema genera dificultades al intentar replicar los resultados, lo que afecta la validación y confiabilidad de los experimentos. Este tema es abordado de manera destacada en el artículo \"Estimating Replicability of Classifier Learning Experiments\", que analiza los retos y las estrategias para evaluar la consistencia y reproducibilidad de los experimentos en el aprendizaje de clasificadores. \n",
    "\n",
    "Existen varios factores específicos que complican la replicabilidad, como los conjuntos de datos sesgados, la variabilidad en la selección de hiperparámetros y las diferencias en el entorno de ejecución, incluyendo hardware, software y versiones de librerías. Para mitigar este problema, es fundamental establecer prácticas estandarizadas, tales como el uso de seeds para garantizar la reproducibilidad, compartir código y datos de manera abierta y seguir protocolos experimentales estrictos. La falta de replicabilidad no solo impacta la investigación académica, sino también la confianza en los modelos aplicados en situaciones del mundo real, con implicaciones que afectan tanto la ciencia como la industria.\n",
    "\n",
    "La prueba t de Student es un análisis estadístico paramétrico que requiere que los datos analizados cumplan ciertas condiciones: deben ser variables de intervalos o razones y seguir una distribución normal. Además, las variables comparadas deben ser independientes entre sí. Por ejemplo, al medir niveles de depresión en grupos de hombres y mujeres o al comparar personas casadas con solteras, es fundamental que estas variables no estén relacionadas para asegurar resultados válidos en el análisis. \n",
    "\n",
    "Es importante señalar que existen diferentes versiones de la prueba t, como la prueba t para muestras independientes, la prueba t para muestras relacionadas (o emparejadas) y la prueba t para una sola muestra, dependiendo del tipo de comparación que se realice. La prueba también asume homogeneidad de varianza entre los grupos; si esta condición no se cumple, la prueba t de Welch puede ser más apropiada. \n",
    "\n",
    "Aunque la normalidad de los datos es una suposición clave, la prueba t puede ser relativamente robusta a pequeñas desviaciones, especialmente con muestras grandes. Asimismo, es útil considerar el cálculo del tamaño del efecto para evaluar la magnitud de la diferencia entre grupos, más allá de su significancia estadística.\n",
    "\n",
    "La prueba t de Student tiene varias limitaciones. Asume que los datos siguen una distribución normal y que las varianzas de los grupos son iguales, lo que puede afectar la validez de los resultados si estas suposiciones no se cumplen. Además, es sensible al tamaño de la muestra, siendo menos confiable en muestras pequeñas. Solo es adecuada para muestras independientes, por lo que no debe usarse en datos emparejados. También puede ser influenciada por valores atípicos y no diferencia entre direcciones específicas de los cambios cuando se usa para dos colas. Estas limitaciones deben ser consideradas al aplicar la prueba t para obtener resultados precisos y válidos.\n",
    "\n",
    "El test de McNemar es una prueba estadística diseñada para identificar cambios en variables categóricas, particularmente en situaciones donde se desea evaluar si existe una diferencia significativa en las proporciones de resultados antes y después de una intervención específica. Para llevar a cabo este análisis, se requieren dos mediciones: una toma de datos inicial previa a la intervención y una segunda medición posterior. El test de McNemar se aplica comúnmente en estudios de tipo antes-después y es particularmente útil cuando se evalúa el impacto de tratamientos, políticas o cualquier intervención en estudios de cohortes emparejadas o muestras dependientes.\n",
    "\n",
    "La prueba es ideal para situaciones donde los datos categóricos son dicotómicos, es decir, con solo dos posibles valores (como \"sí\" o \"no\", \"presente\" o \"ausente\"). El objetivo principal es evaluar si la proporción de cambios en una dirección (por ejemplo, de \"no\" a \"sí\") difiere significativamente de la proporción de cambios en la dirección opuesta (\"sí\" a \"no\"). \n",
    "\n",
    "Esto la convierte en una herramienta valiosa para comparar resultados cuando los mismos individuos son evaluados en ambos momentos y, por lo tanto, sus respuestas están emparejadas. Además, el test de McNemar es no paramétrico, lo que lo hace robusto para muestras de tamaño pequeño y para datos que no cumplen con los supuestos de normalidad.\n",
    "\n",
    "El test de McNemar tiene varias limitaciones. Solo es aplicable a datos con dos categorías, lo que restringe su uso en situaciones con más de dos opciones. Además, no mide la magnitud del cambio, solo la significancia de la diferencia en proporciones. Su efectividad también puede verse afectada por el tamaño de la muestra, ya que en muestras pequeñas puede tener baja potencia estadística. El test asume la independencia entre los pares de datos, lo que puede ser problemático si esta suposición no se cumple. Además, no distingue entre las direcciones de los cambios y no es adecuado para realizar múltiples comparaciones sin ajustar el nivel de significancia para evitar falsos positivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen de las tecnicas\n",
    "Para esta práctica, se propone desarrollar dos clasificadores y comparar sus métricas de rendimiento utilizando la prueba t de Student y el test de McNemar.\n",
    "\n",
    "Para garantizar la replicabilidad en esta práctica, hemos concluido que la mejor opción es utilizar la validación 5x2. Por lo tanto, para entrenar los dos modelos correspondientes, aplicaremos este método de validación en ambos casos.\n",
    "## Resumen Tecnica: Test de McNeamar\n",
    "como se realiza?\n",
    "en que esta basada? (breve introduccion teorica)\n",
    "puntos fuertes y debiles de esta tecnica\n",
    "### ¿Cómo se realiza? \n",
    "El test de McNemar es una prueba estadística utilizada para comparar dos proporciones en datos emparejados, especialmente cuando se tiene información categórica con dos posibles resultados. Se emplea cuando se quiere evaluar si hay cambios significativos en las respuestas de los participantes antes y después de una intervención o entre dos condiciones de un mismo grupo. Para llevarlo a cabo, se utiliza una tabla de contingencia 2x2 con las siguientes categorías:\n",
    "\n",
    "- A1B1: Casos en los que ambos grupos tienen la misma respuesta (antes y después o en ambas condiciones).\n",
    "- A1B2: Casos en los que el grupo tenía una respuesta en el primer momento y otra diferente en el segundo.\n",
    "- A2B1: Casos en los que el grupo tenía una respuesta diferente al principio y la misma al final.\n",
    "- A2B2: Casos donde ambos grupos tienen respuestas diferentes.\n",
    "\n",
    "El test se basa en la diferencia entre los casos A1B2 y A2B1, comparando el número de cambios en una dirección con el número de cambios en la otra dirección. La fórmula para calcular el estadístico  $ X^{2} $  es: $ X^{2} = \\frac{(b-c)^{2}}{{b+c}}$, donde b y c son los valores de las categorías A1B2 y A2B1, respectivamente.\n",
    "\n",
    "### ¿En qué está basado? \n",
    "El test de McNemar se basa en una distribución binomial y en la hipótesis de que, si no existe un cambio significativo entre las dos mediciones o condiciones, los cambios de categoría (de A1 a A2 o de B1 a B2) deben ser aproximadamente simétricos. Esta prueba es especialmente útil en estudios de medidas repetidas, como en investigaciones psicológicas, clínicas y de salud, donde se mide la misma variable en dos momentos diferentes o bajo dos condiciones distintas.\n",
    "\n",
    "### Puntos fuertes:\n",
    "- Simplicidad y aplicación directa: Es fácil de implementar cuando se tienen datos categóricos emparejados.\n",
    "- Adecuado para datos pequeños: Funciona bien incluso con muestras pequeñas, a diferencia de otras pruebas estadísticas.\n",
    "- Control de sesgo de selección: Al comparar resultados de la misma unidad de observación en dos momentos o condiciones, minimiza posibles sesgos.\n",
    "\n",
    "### Puntos débiles:\n",
    "- Restricciones en la estructura de los datos: Solo se utiliza con datos dicotómicos (dos categorías) y con muestras emparejadas.\n",
    "- Sensibilidad limitada: No es adecuado para situaciones con muchas respuestas neutrales o indeterminadas, ya que solo se enfoca en los cambios significativos entre las categorías.\n",
    "- Requiere un número adecuado de cambios: Si las diferencias entre las categorías son muy pequeñas (es decir, pocos casos en A1B2 y A2B1), los resultados pueden no ser significativos.\n",
    "\n",
    "## Resumen Tecnica: Test de t de Student\n",
    "### ¿Cómo se realiza? \n",
    "El test t de Student es una prueba estadística que se utiliza para comparar las medias de dos grupos y determinar si existe una diferencia significativa entre ellas. Existen dos versiones del test t:\n",
    "- Test t para muestras independientes: Compara las medias de dos grupos independientes entre sí.\n",
    "- Test t para muestras relacionadas (o apareadas): Compara las medias de dos grupos relacionados, como las mediciones de un mismo grupo antes y después de una intervención.\n",
    "La fórmula básica para calcular el estadístico t es:\n",
    "\n",
    "$  t = \\frac{\\overline{X_{1}} - \\overline{X_2}}{\\sqrt{\\frac{s_{1}^{2}}{n_1} + \\frac{s_{2}^2}{n_2}}} $\n",
    "\n",
    "donde:\n",
    "- $ \\overline{X_1} $ y $ \\overline{X_1} $ son las medias de los dos grupos.\n",
    "- $ s_{1}^{2} $ y $ s_{2}^{2} $ son las varianzas de los dos grupos.\n",
    "- $ n_1 $ y $ n_2 $ son los tamaños de las muestras.\n",
    "\n",
    "\n",
    "El valor de t se compara con una distribución t de Student para determinar la significancia de la diferencia entre las medias.\n",
    "\n",
    "### ¿En qué está basado?\n",
    "El test t de Student se basa en la teoría de la estimación de la media de una población a partir de una muestra. Asume que los datos siguen una distribución normal y que las varianzas de las dos poblaciones que se comparan son iguales (en el caso del test t para muestras independientes). Este test se utiliza en contextos donde las muestras son relativamente pequeñas y la distribución normal de los datos se asume o se puede verificar.\n",
    "\n",
    "### Puntos fuertes\n",
    "- Facilidad de aplicación: Es ampliamente utilizado en muchos campos de investigación debido a su simplicidad y fiabilidad para comparar dos medias.\n",
    "- Versatilidad: Puede aplicarse tanto a muestras independientes como relacionadas.\n",
    "- Eficiencia con muestras pequeñas: A diferencia de otros test estadísticos, el test t es útil incluso cuando las muestras son pequeñas, siempre que se cumplan las suposiciones de normalidad.\n",
    "\n",
    "### Puntos débiles\n",
    "- Asume normalidad: Requiere que los datos se distribuyan de manera aproximadamente normal. Si los datos no cumplen esta suposición, los resultados pueden ser sesgados.\n",
    "- Sensibilidad a varianzas desiguales: En el caso de muestras independientes, si las varianzas de los grupos no son iguales, el test puede ser inapropiado o menos preciso, aunque existen ajustes (como el test t de Welch).\n",
    "- No adecuado para muestras grandes con varianzas desconocidas: En casos de muestras grandes, otros test como el análisis de varianza (ANOVA) podrían ser más apropiados si se comparan más de dos grupos.\n",
    "\n",
    "## 5x2 crossvalidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necesarios del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del dataset\n",
    "En este proyecto, uno de los elementos clave es seleccionar un dataset adecuado para entrenar y evaluar nuestro modelo de machine learning. En particular, necesitamos un conjunto de datos que cumpla con ciertos requisitos específicos para aplicar el test t de Student, el test de McNemar y 5x2 crossvalidation.\n",
    "\n",
    "Requisitos del Dataset\n",
    "- Número de Instancias: Debido a que vamos a utilizar la técnica de validación cruzada 5X2 (5-fold cross-validation con 2 repeticiones), es fundamental contar con un dataset que tenga una cantidad significativa de instancias. Este tipo de validación cruzada implica dividir el dataset en 5 subconjuntos (folds) y realizar 2 repeticiones del proceso.\n",
    "\n",
    "- Variables Categóricas: Para este ejercicio, necesitamos un modelo que prediga una variable categórica. Esto es necesario porque las métricas de evaluación, como el test t de Student y el test de McNemar, se aplican específicamente a este tipo de variables\n",
    "\n",
    "El conjunto de datos elegido para esta práctica es el conocido [\"Adult Income Dataset\"](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset) (también llamado \"Census Income Dataset\"). El objetivo de este dataset es predecir si una persona gana más de 50,000 dólares anuales o no, basándose en variables como la edad, el nivel educativo, la ocupación, el estado civil, el número de horas trabajadas por semana, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../Datasets/adult.csv') # https://www.kaggle.com/datasets/wenruliu/adult-income-dataset\n",
    "df = df_all.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario convertir todos los datos de tipo \"object\" a enteros, ya que estos son variables categóricas con valores específicos asignados. Para que el modelo pueda procesar correctamente estos datos, primero los transformaremos a un formato categórico, asignando un código único a cada categoría. Luego, convertiremos estas variables categóricas a valores enteros, lo que permitirá que el modelo pueda evaluarlas y utilizarlas en el entrenamiento. Esta transformación es esencial para que los modelos puedan interpretar las relaciones entre las distintas categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   age              48842 non-null  int64\n",
      " 1   workclass        48842 non-null  int8 \n",
      " 2   fnlwgt           48842 non-null  int64\n",
      " 3   education        48842 non-null  int8 \n",
      " 4   educational-num  48842 non-null  int64\n",
      " 5   marital-status   48842 non-null  int8 \n",
      " 6   occupation       48842 non-null  int8 \n",
      " 7   relationship     48842 non-null  int8 \n",
      " 8   race             48842 non-null  int8 \n",
      " 9   gender           48842 non-null  int8 \n",
      " 10  capital-gain     48842 non-null  int64\n",
      " 11  capital-loss     48842 non-null  int64\n",
      " 12  hours-per-week   48842 non-null  int64\n",
      " 13  native-country   48842 non-null  int8 \n",
      " 14  income           48842 non-null  int8 \n",
      "dtypes: int64(6), int8(9)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['workclass', 'education', 'marital-status','occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "# Convertir las columnas de object a categóricas\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')  # Convertir a categórico\n",
    "\n",
    "# Convertir categorías a enteros\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].cat.codes  # Convertir a códigos numéricos\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, debemos dividir los datos en dos conjuntos, X (características) e Y (etiquetas). Luego, solo escalaremos el vector X, ya que escalar Y no tiene sentido, dado que representa las etiquetas o valores objetivo que no requieren normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values  # Todas las columnas excepto la última\n",
    "y = df.iloc[:, -1].values   # Solo la última columna\n",
    "\n",
    "# Escalar las características (X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los Modelos y Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados 5x2:\n",
      "[LGR] Scores: [0.82461816 0.82494574 0.82617419 0.82433152 0.82748454 0.82166987\n",
      " 0.82691126 0.82310307 0.82371729 0.82523238]\n",
      "[LGR] Promedio de scores: 0.8248188034888007\n",
      "****\n",
      "[SVM] Scores: [0.81823021 0.80873019 0.81176037 0.81425822 0.81544572 0.81118709\n",
      " 0.8148315  0.81167847 0.81319356 0.81372589]\n",
      "[SVM] Promedio de scores: 0.8133041235002662\n"
     ]
    }
   ],
   "source": [
    "# Configuración de 5x2 Cross-Validation\n",
    "# n_repeats = 5  # Número de repeticiones\n",
    "kf = RepeatedKFold(n_splits=2, n_repeats=5, random_state=42)  # KFold con 2 splits\n",
    "\n",
    "# Modelo a evaluar\n",
    "model = LogisticRegression()\n",
    "svm_model = SVC(kernel='linear')  # Puedes probar también otros kernels como 'rbf'\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "# scores_logistic = []\n",
    "scores_svm = []\n",
    "\n",
    "scores_logistic = cross_val_score(model, X, y, cv=kf)\n",
    "scores_svm = cross_val_score(svm_model, X, y, cv=kf)\n",
    "\n",
    "# Mostrar resultados finales\n",
    "print(\"\\nResultados 5x2:\")\n",
    "print(\"[LGR] Scores:\", scores_logistic)\n",
    "print(\"[LGR] Promedio de scores:\", np.mean(scores_logistic))\n",
    "print(\"****\")\n",
    "print(\"[SVM] Scores:\", scores_svm)\n",
    "print(\"[SVM] Promedio de scores:\", np.mean(scores_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
