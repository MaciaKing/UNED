{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breve resumen Teorico del problema\n",
    "El problema de la replicabilidad en la actualidad representa un desafío significativo, especialmente en el campo del machine learning, donde la variedad de modelos desarrollados es amplia y diversa. \n",
    "\n",
    "La existencia de múltiples modelos para resolver un mismo problema genera dificultades al intentar replicar los resultados, lo que afecta la validación y confiabilidad de los experimentos. Este tema es abordado de manera destacada en el artículo \"Estimating Replicability of Classifier Learning Experiments\", que analiza los retos y las estrategias para evaluar la consistencia y reproducibilidad de los experimentos en el aprendizaje de clasificadores. \n",
    "\n",
    "Existen varios factores específicos que complican la replicabilidad, como los conjuntos de datos sesgados, la variabilidad en la selección de hiperparámetros y las diferencias en el entorno de ejecución, incluyendo hardware, software y versiones de librerías. Para mitigar este problema, es fundamental establecer prácticas estandarizadas, tales como el uso de seeds para garantizar la reproducibilidad, compartir código y datos de manera abierta y seguir protocolos experimentales estrictos. La falta de replicabilidad no solo impacta la investigación académica, sino también la confianza en los modelos aplicados en situaciones del mundo real, con implicaciones que afectan tanto la ciencia como la industria.\n",
    "\n",
    "La prueba t de Student es un análisis estadístico paramétrico que requiere que los datos analizados cumplan ciertas condiciones: deben ser variables de intervalos o razones y seguir una distribución normal. Además, las variables comparadas deben ser independientes entre sí. Por ejemplo, al medir niveles de depresión en grupos de hombres y mujeres o al comparar personas casadas con solteras, es fundamental que estas variables no estén relacionadas para asegurar resultados válidos en el análisis. \n",
    "\n",
    "Es importante señalar que existen diferentes versiones de la prueba t, como la prueba t para muestras independientes, la prueba t para muestras relacionadas (o emparejadas) y la prueba t para una sola muestra, dependiendo del tipo de comparación que se realice. La prueba también asume homogeneidad de varianza entre los grupos; si esta condición no se cumple, la prueba t de Welch puede ser más apropiada. \n",
    "\n",
    "Aunque la normalidad de los datos es una suposición clave, la prueba t puede ser relativamente robusta a pequeñas desviaciones, especialmente con muestras grandes. Asimismo, es útil considerar el cálculo del tamaño del efecto para evaluar la magnitud de la diferencia entre grupos, más allá de su significancia estadística.\n",
    "\n",
    "La prueba t de Student tiene varias limitaciones. Asume que los datos siguen una distribución normal y que las varianzas de los grupos son iguales, lo que puede afectar la validez de los resultados si estas suposiciones no se cumplen. Además, es sensible al tamaño de la muestra, siendo menos confiable en muestras pequeñas. Solo es adecuada para muestras independientes, por lo que no debe usarse en datos emparejados. También puede ser influenciada por valores atípicos y no diferencia entre direcciones específicas de los cambios cuando se usa para dos colas. Estas limitaciones deben ser consideradas al aplicar la prueba t para obtener resultados precisos y válidos.\n",
    "\n",
    "El test de McNemar es una prueba estadística diseñada para identificar cambios en variables categóricas, particularmente en situaciones donde se desea evaluar si existe una diferencia significativa en las proporciones de resultados antes y después de una intervención específica. Para llevar a cabo este análisis, se requieren dos mediciones: una toma de datos inicial previa a la intervención y una segunda medición posterior. El test de McNemar se aplica comúnmente en estudios de tipo antes-después y es particularmente útil cuando se evalúa el impacto de tratamientos, políticas o cualquier intervención en estudios de cohortes emparejadas o muestras dependientes.\n",
    "\n",
    "La prueba es ideal para situaciones donde los datos categóricos son dicotómicos, es decir, con solo dos posibles valores (como \"sí\" o \"no\", \"presente\" o \"ausente\"). El objetivo principal es evaluar si la proporción de cambios en una dirección (por ejemplo, de \"no\" a \"sí\") difiere significativamente de la proporción de cambios en la dirección opuesta (\"sí\" a \"no\"). \n",
    "\n",
    "Esto la convierte en una herramienta valiosa para comparar resultados cuando los mismos individuos son evaluados en ambos momentos y, por lo tanto, sus respuestas están emparejadas. Además, el test de McNemar es no paramétrico, lo que lo hace robusto para muestras de tamaño pequeño y para datos que no cumplen con los supuestos de normalidad.\n",
    "\n",
    "El test de McNemar tiene varias limitaciones. Solo es aplicable a datos con dos categorías, lo que restringe su uso en situaciones con más de dos opciones. Además, no mide la magnitud del cambio, solo la significancia de la diferencia en proporciones. Su efectividad también puede verse afectada por el tamaño de la muestra, ya que en muestras pequeñas puede tener baja potencia estadística. El test asume la independencia entre los pares de datos, lo que puede ser problemático si esta suposición no se cumple. Además, no distingue entre las direcciones de los cambios y no es adecuado para realizar múltiples comparaciones sin ajustar el nivel de significancia para evitar falsos positivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnicas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame from the dataset for better readability\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7 \n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(f\"Accuracy: {results.mean()*100.0:,.2F}% ({results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
