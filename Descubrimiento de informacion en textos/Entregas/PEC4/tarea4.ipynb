{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos las ejecuciones de la tarea anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de cabeceras.\n",
    "Se ha realizado en la Tarea 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd() + \"/Corpus-representacion\"\n",
    "# Obtener el listado\n",
    "listado = os.listdir(path)\n",
    "corpus_dir = [] # Guardamos el directorio para cada fichero\n",
    "for elemento in listado:\n",
    "    corpus_dir.append(path +'/'+elemento)\n",
    "\n",
    "all_corpus_files = []\n",
    "for dir in corpus_dir:\n",
    "    corpus_files = os.listdir(dir)\n",
    "    for corpus in corpus_files:\n",
    "        all_corpus_files.append(dir +'/'+corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk.politics.mideast',\n",
       " 'rec.autos',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.sport.hockey',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'sci.electronics',\n",
       " 'talk.politics.guns']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(ruta_fichero):\n",
    "    \"\"\"\n",
    "    Lee el contenido de un fichero de texto y lo retorna como un string único.\n",
    "    \n",
    "    Args:\n",
    "        ruta_fichero (str): Ruta al archivo de texto.\n",
    "        \n",
    "    Returns:\n",
    "        str: Contenido completo del fichero como una única cadena.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ruta_fichero, 'r', encoding='utf-8') as fichero:\n",
    "            contenido = fichero.read()\n",
    "        return contenido\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: El fichero no se encuentra.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for corpus in all_corpus_files:\n",
    "    for tema in listado:\n",
    "        if tema in corpus:\n",
    "            data.append((read_file(corpus), tema))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(805, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns=['content', 'class'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "La tokenización es el proceso de dividir un texto en unidades más pequeñas, conocidas como \"tokens\", que pueden ser palabras, frases o incluso caracteres. Este paso es crucial en el procesamiento de lenguaje natural (NLP) para convertir texto no estructurado en una forma que las máquinas puedan entender y analizar. La tokenización permite descomponer un documento en componentes manejables, como palabras individuales o sub-palabras, que posteriormente se utilizan en tareas como clasificación de texto, análisis de sentimientos, traducción automática, entre otras.\n",
    "\n",
    "En el siguiente código, hemos estandarizado la entrada de las palabras eliminando aquellos términos que contienen símbolos como !, :, entre otros caracteres. Además, hemos convertido todos los caracteres a minúsculas, ya que esto mejorará el rendimiento de nuestro algoritmo. También hemos añadido un delimitador **@@@** al final de cada documento; en los pasos posteriores explicaremos el motivo de utilizar estos delimitadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Message-ID: <FLAX.93Apr6125933@frej.teknikum.uu.se>References: <1993Mar30.142700.543@vms.huji.ac.il> <FLAX.93Apr3142133@frej.teknikum.uu.se><FLAX.93Apr5224449@frej.teknikum.uu.se><1993Apr5.221759.28472@thunder.mcrcim.mcgill.edu>NNTP-Posting-Host: frej.teknikum.uu.seIn-reply-to: hasan@McRCIM.McGill.EDU \\'s message of Mon, 5 Apr 93 22:17:59 GMTIn article <1993Apr5.221759.28472@thunder.mcrcim.mcgill.edu> hasan@McRCIM.McGill.EDU  writes:[ stuff deleted ]|> I wrote:|> Are you calling names, or giving me a title? If the first, read your|> paragraph above, if not I accept the title, in order to let you get into the|> um, well, debate again.Hasan replies:I didnot know that \"Master of wisdom\" can be \"name clling\" too,unless you consider yourself deserve-less !Unless you are referring to someone else, you have in fact given me a nameI did not ask for, hence the term \\'name calling\\'.Hasan writes:|>    So what do you expect me to tell you to tell you, Master of Wsidom,|> \\t\\t\\t\\t\\t\\t\\t       ^^^|> ------------------------------------------------------------------I replied:|> If you insist on giving me names/titles I did not ask for you could at|> least spell them correctly. /sigh.Hasan gloats:That was only to confuse you! (ha ha ha hey )Hell-bent on retarding into childhood, no?|>when you are intentionally neglecting the MOST important fact that|>the whole israeli presence in the occupied territories is ILLEGITIMATE,|>and hence ALL their actions, their courts, their laws are illegitimate on|>the ground of occupied territories.|>>No, I am _not_ neglecting that, I\\'m merely asking you whether the existance>of Israeli citicens in the WB or in Gaza invalidates those individuals>right^^^^^^^ are you trying to retaliate and confuse me here.No, I really do try to spell correctly, and I apologize if I did confuse you.I will try not to repeat that.|> to live, a (as you so eloquently put it) human right. We can get back to the|> question of which law should be used in the territories later. Also, you have|> not adressed my question if the israelis also have human rights.First, my above statement doesnot say that \"the existence of israeli citizensin the WB revoke their right of life\" but it says \"the israeli occupationof the WB revoke the right of life for some/most its citizens - basicallyrevokes the right of for its military men\". Clearly, occupation is anundeclared war; during war, attacks against military targets are fully legitimate.Ok, let me re-phrase the question. I have repeatedly asked you if theIsraelis have less human rights than the palestinians, and if so, why.From your posting (where you did not directly adress my question) I inferredthat you thought so. Together with the above statement I then assumed that thereason was the actions of the state of Israel. Re: your statement ofoccupation: I\\'d like you to define the term, so I don\\'t have to repeat this\\'drag the answer out of hasan\\' procedure more than neccesary.Secondly, surely israeli have human rights, but they ask their goverment toprotect it by withdrawing from the occupied terretories, not by further oppressingPalestinean human rights.I\\'m sorry, but the above sentence does not make sense. Please rephrase it.|> If a state can deprive all it\\'s citizens of human rights by its actions, then|> tell me why _any_ human living today should have any rights at all?Because not all states are like Israel, as oppressive, as ignorant, or as tyrant.Oh, ok. So how about the human rights of the Syrians, Iraqis and others?Does the name of Hama sound familiar? Or how about the kurds in Iraq andTurkey?How about the Same in Sweden (Ok, maybe a bit farfetched..) the Russians inthe Baltic states or the Moslem in the old USSR and Yugoslavia?Do the serbs have any human rights remainaing, according to you?|>    |> And which system do you propose we use to solve the ME problem?|>|>    The question is NOT which system would solve the ME problem. Why ? because|>    any system can solve it.|>    The laws of minister Sharon says kick Palestineans out of here (all palestine).|>|> I asked for which system should be used, that will preserve human rights for^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^|> all people involved. I assumed that was obvious, but I won\\'t repeat that|> mistake. Now that I have straightened that out, I\\'m eagerly awaiting your|> reply.So you agree that that an israeli solution wouldnot preserve human rights.(i am understanding this from your first statement in this paragraph).No, I\\'m agreeing that to just kick all the Palestinians out of Israel properwould probably lead to disaster for both parties. If that\\'s what you referto as the \\'Israeli solution\\' then so be it.|>    Joseph Weitz (administrator responsible for Jewish colonization)|>    said it best when writing in his diary in 1940:|> \\t   \"Between ourselves it must be clear that there is no room for both|> \\t   peoples together in this country.... We shall not achieve our goal|> \\t\\t\\t\\t\\t\\t^^^                  ^^^|> \\t   of being an independent people with the Arabs in this small country.|> \\t   The only solution is a Palestine, at least Western Palestine (west of|> \\t   the Jordan river) without Arabs.... And there is no other way than|> \\t   to transfer the Arabs from here to the neighbouring countries, to|> \\t   transfer all of them; not one village, not one tribe, should be|> \\t   left.... Only after this transfer will the country be able to|> \\t   absorb the millions of our own brethren. There is no other way out.\"|> \\t\\t\\t\\t   DAVAR, 29 September, 1967|> \\t\\t\\t\\t   (\"Courtesy\" of Marc Afifi)|>|> Just a question: If we are to disregard the rather obvious references to|> getting Israel out of ME one way or the other in both PLO covenant and HAMAS|> charter (that\\'s the english translations, if you have other information I\\'d|> be interested to have you translate it) why should we give any credence to|> a _private_ paper even older? I\\'m not going to get into the question if he|> wrote the above, but it\\'s fairly obvious all parties in the conflict have|> their share of fanatics. Guess what..? Those are not the people that will|> make any lasting peace in the region. [more deleted stuff]>Exactly, you are right. I guess that the problem is that the israeli goverment>is full with  men like Joseph Weitz.Oh? Have you met with them personally, to read their diaries? Fascinating.What do you _do_ for a living?|>    \"We\" and \"our\" either refers to Zionists or Jews (i donot know which).|>|>    Well, i can give you an answer, you Master of Wisdom, I will NOT suggest the|>    imperialist israeli system for solving the ME problem !|>|>    I think that is fair enough .|>|> No, that is _not_ an answer, since I asked for a system that could solve|> the problem. You said any could be used, then you provided a contradiction.Above you wrote that you understood what i meant (underlined by ^ ):any system can be used to solve the conflict , but not any system wouldresolve it JUSTLY.An unjust solution would be a non-solution, per definition, no?You said the following:For all A it holds that A have property B.There exists an A such that property B does not hold.Thus, either or both statements must be false.|> Guess where that takes your logic? To never-never land.>You are proving yourself as a \" \". First you understood what i meant, but then>you claim you didnot so to claim a contradiction in my logic.>Too bad for you, the Master of Wisdom.I was merely pointing out a not so small flaw in your reasoning.Since you claim to be logical I felt it best to point this outbefore you started using your statements to prove a point or so.Am I then to assume you are  not logical?|>    \"The greatest problem of Zionism is Arab children\".|> \\t\\t\\t   -Rabbi Shoham.|>|> Oh, and by the way, let me add that these cute quotes you put at the end are|> a real bummer, when I try giving your posts any credit.>Why do you feel ashamed by things and facts that you believe in ,>if you were a Zionists. If you believe in Zionist codes and acts,>well i feel sorry for you, because the same Rabbi Shoham had said>\"Yes, Zionism is racism\".>If you feel ashamed and bothered by the Zionist codes, then drop Zionism.>If you are not Zionist, why are you bothered then. You should join me in>condemning these racist Zionist codes and acts.Any quote can be misused, especially when used to stereotype allindividuals by a statement of an individual. If you use the samemethods that you credit \\'Zionists\\' with, then where does that place you?Oh, by the way, I\\'d advice you not to assume anything about my \\'loyalties\\'.I will and am condemning acts I find vile and inhuman, but I\\'ll try aslong as I can not to assume those acts are by a whole people.By zionist above do you mean the state of Israel, the government of Israel,the leaders of Israel (political and/or religious) or the jews ingeneral? If you feel the need to condemn, condemn those responsibleinstead. How would you feel if we started condemning you personallybased on the bombings in Egypt?----------------------------------------------------------Jonas Flygare, \\t\\t+ Wherever you go, there you areV{ktargatan 32 F:621\\t+754 22 Uppsala, Sweden\\t+'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello small go go god afternoon a i'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words as nltk_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "# nltk.download('words')\n",
    "\n",
    "valid_words = set(nltk_words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_string_to_array(string_to_convert):\n",
    "    # Dividir la cadena en palabras, eliminando espacios en blanco\n",
    "    return [word for word in string_to_convert.split(' ') if word]\n",
    "\n",
    "def remove_all_words_that_contain_numbers(list_of_words):\n",
    "    # Verifica que cada elemento en la lista no contenga números\n",
    "    return [word for word in list_of_words if not re.search(r'\\d', word)]\n",
    "\n",
    "def filter_word_by_lenght(list_of_words):\n",
    "    exceptions = ['i', 'a']\n",
    "    return [word for word in list_of_words if 2 <= len(word) <= 15 or word in exceptions]\n",
    "\n",
    "def filter_stop_words(list_of_words):\n",
    "    filtered_bag_of_words = []\n",
    "    for word in list_of_words:\n",
    "        if word not in stop_words:\n",
    "            filtered_bag_of_words.append(word)\n",
    "    return filtered_bag_of_words\n",
    "\n",
    "def word_exists(list_of_words):\n",
    "    return [word for word in list_of_words if word in valid_words or word == '@@@']\n",
    "\n",
    "def array_to_string(list_of_words):\n",
    "    return ' '.join(list_of_words)\n",
    "\n",
    "# Función para mapear tipos gramaticales\n",
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def apply_lemmatizer(list_of_words):\n",
    "    return [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in list_of_words]\n",
    "\n",
    "def preproces(data):\n",
    "    preproces_data = convert_string_to_array(data)\n",
    "    preproces_data = remove_all_words_that_contain_numbers(preproces_data)\n",
    "    preproces_data = filter_word_by_lenght(preproces_data)\n",
    "    preproces_data = word_exists(preproces_data)\n",
    "    preproces_data = filter_stop_words(preproces_data)\n",
    "    preproces_data = apply_lemmatizer(preproces_data)\n",
    "    return array_to_string(preproces_data)\n",
    "\n",
    "\n",
    "test = \"hello smaller macia2345 going gone asdfasdf45 god afternoon a i m\"\n",
    "test = convert_string_to_array(test)\n",
    "test = remove_all_words_that_contain_numbers(test)\n",
    "test = filter_word_by_lenght(test)\n",
    "test = word_exists(test)\n",
    "test = apply_lemmatizer(test)\n",
    "test = array_to_string(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Message-ID: &lt;FLAX.93Apr6125933@frej.teknikum.u...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In article &lt;1993Apr5.202800.27705@wam.umd.edu&gt;...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPOSITION of VITALY NIKOLAYEVICH DANIELIAN [1...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nntp-Posting-Host: saluda.columbiasc.ncr.comIn...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;iacovou.734063606@gurney&gt; iacovou@...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                  class\n",
       "0  Message-ID: <FLAX.93Apr6125933@frej.teknikum.u...  talk.politics.mideast\n",
       "1  In article <1993Apr5.202800.27705@wam.umd.edu>...  talk.politics.mideast\n",
       "2  DEPOSITION of VITALY NIKOLAYEVICH DANIELIAN [1...  talk.politics.mideast\n",
       "3  Nntp-Posting-Host: saluda.columbiasc.ncr.comIn...  talk.politics.mideast\n",
       "4  In article <iacovou.734063606@gurney> iacovou@...  talk.politics.mideast"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'content'] = preproces(row['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>message of article stuff you calling or giving...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article Bonnie of article do who even believe ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of School at people in town know what was happ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article is getting are breaking the article in...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article even the most uncivilized of have of c...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                  class\n",
       "0  message of article stuff you calling or giving...  talk.politics.mideast\n",
       "1  article Bonnie of article do who even believe ...  talk.politics.mideast\n",
       "2  of School at people in town know what was happ...  talk.politics.mideast\n",
       "3  article is getting are breaking the article in...  talk.politics.mideast\n",
       "4  article even the most uncivilized of have of c...  talk.politics.mideast"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>message of article stuff you calling or giving...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>[message, of, article, stuff, you, calling, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article Bonnie of article do who even believe ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>[article, Bonnie, of, article, do, who, even, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of School at people in town know what was happ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>[of, School, at, people, in, town, know, what,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article is getting are breaking the article in...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>[article, is, getting, are, breaking, the, art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article even the most uncivilized of have of c...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>[article, even, the, most, uncivilized, of, ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                  class  \\\n",
       "0  message of article stuff you calling or giving...  talk.politics.mideast   \n",
       "1  article Bonnie of article do who even believe ...  talk.politics.mideast   \n",
       "2  of School at people in town know what was happ...  talk.politics.mideast   \n",
       "3  article is getting are breaking the article in...  talk.politics.mideast   \n",
       "4  article even the most uncivilized of have of c...  talk.politics.mideast   \n",
       "\n",
       "                                              tokens  \n",
       "0  [message, of, article, stuff, you, calling, or...  \n",
       "1  [article, Bonnie, of, article, do, who, even, ...  \n",
       "2  [of, School, at, people, in, town, know, what,...  \n",
       "3  [article, is, getting, are, breaking, the, art...  \n",
       "4  [article, even, the, most, uncivilized, of, ha...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column for Word2Vec\n",
    "df['tokens'] = df['content'].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de pesado TF y TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (805, 5802)\n",
      "Feature Names: ['abandoned' 'abiding' 'ability' ... 'zone' 'zucchini' 'zulu']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Suponiendo que tu DataFrame se llama 'df' y la columna de texto es 'content'\n",
    "contents = df['content']\n",
    "\n",
    "# Crear un objeto TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar los datos de texto a TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(contents)\n",
    "\n",
    "# tfidf_matrix es una matriz dispersa (sparse matrix). Si deseas convertirla a una matriz densa:\n",
    "dense_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# Opcional: Obtener los nombres de las características (palabras o términos únicos)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)  # Dimensiones: (número de documentos, número de términos)\n",
    "print(\"Feature Names:\", feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más similares a 'article': [('Jason', 0.8123925924301147), ('am', 0.7839433550834656), ('message', 0.7601901888847351), ('read', 0.7472124099731445), ('about', 0.715707004070282)]\n",
      "Vector para 'article': [-0.30588853  0.2768493  -0.15653813 -0.01074309 -0.02767886 -0.02225285\n",
      "  0.19732454  0.21759912  0.03973274  0.12874821  0.27892548 -0.6338676\n",
      "  0.17702127 -0.03644745  0.16711238 -0.11877959 -0.01292252 -0.02337271\n",
      " -0.0452549   0.09049419 -0.16342013 -0.24691194 -0.17946075 -0.11492638\n",
      "  0.05154823  0.0882732  -0.22497827  0.10889766 -0.26830366 -0.3273254\n",
      " -0.2232684  -0.08670915  0.2755796  -0.11315802 -0.2654038   0.32977548\n",
      "  0.28554755  0.21898916 -0.49614552  0.13591675 -0.1149618   0.17802273\n",
      "  0.22116116 -0.36805755  0.41195393 -0.2840177   0.05711083 -0.17387007\n",
      "  0.38688904  0.371374    0.27710453 -0.09631194 -0.16103676 -0.16869402\n",
      "  0.04634953 -0.23770972  0.20871618 -0.10144551  0.41607937 -0.08494373\n",
      " -0.04631688 -0.08393058 -0.0280866   0.10491826 -0.08547763  0.12523556\n",
      " -0.35372424  0.6020228  -0.11838923 -0.11627847  0.37434953  0.2507409\n",
      "  0.15498246  0.18876016  0.86125475  0.1629901   0.09152211 -0.20010528\n",
      "  0.22712167  0.22242084 -0.354986   -0.37214303 -0.5593397   0.281838\n",
      "  0.10039732 -0.41417378 -0.00817451  0.13374051  0.40656224  0.21032947\n",
      " -0.13924326  0.16285259  0.17215975  0.08704809  0.6805969   0.40344486\n",
      "  0.24657723  0.02683407 -0.03614625 -0.21168667]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Entrenar el modelo Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences=df['tokens'],  # Lista de listas de palabras\n",
    "    vector_size=100,         # Dimensión de los vectores\n",
    "    window=5,                # Contexto de palabras (tamaño de la ventana)\n",
    "    min_count=2,             # Mínimo número de ocurrencias para considerar una palabra\n",
    "    workers=4,               # Número de hilos (núcleos de CPU)\n",
    "    sg=1                     # Skip-gram (1) o CBOW (0)\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado (opcional)\n",
    "# model.save(\"word2vec_model\")\n",
    "\n",
    "# Opcional: Cargar el modelo posteriormente\n",
    "# model = Word2Vec.load(\"word2vec_model\")\n",
    "\n",
    "# Inspeccionar las palabras más similares a un término\n",
    "similar_words = model.wv.most_similar(\"article\", topn=5)\n",
    "print(\"Palabras más similares a 'article':\", similar_words)\n",
    "\n",
    "# Obtener el vector de una palabra\n",
    "vector = model.wv['article']\n",
    "print(\"Vector para 'article':\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "https://www.kaggle.com/code/aybukehamideak/clustering-text-documents-using-k-means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
