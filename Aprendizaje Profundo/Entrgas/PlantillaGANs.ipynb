{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6768877-ec9c-4aed-ba86-667924607ff5",
   "metadata": {
    "id": "e6768877-ec9c-4aed-ba86-667924607ff5",
    "tags": []
   },
   "source": [
    "# PEC1 - Generative Adversarial Networks\n",
    "A partir del conjunto de datos CIFAR10, se debe entrenar una *DCGAN* (*Deep Convolutional Generative Adversarial Network*) para generar nuevas imágenes. Una vez implementada la red, se deberá agregar *experience replay* y comparar los resultados con los obtenidos en la red inicial. Por último, se deberá convertir la red en una GAN condicional. \n",
    "\n",
    "## Instrucciones\n",
    "Se debe contestar a cada apartado de la práctica en el espacio correspondiente de esta plantilla. Los apartados que se deben contestar en lenguaje natural (utilizando las celdas de tipo Markdown), se han resaltado en amarillo. Se debe añadir debajo del texto resaltado la respuesta correspondiente. Cuando el texto subrayado indique algún requisito de la respuesta (por ejemplo en cuanto a longitud de la respuesta), será imprescindible ajustarse a dicho requisito. Los apartados que requieren código en Python deberán contestarse en los espacios de código previstos para ello. Al igual que las respuestas en celdas de tipo markdown, las respuestas de código pueden tener asociados requisitos especiales. Estos espacios se delimitan con la siguiente estructura:\n",
    "``` python\n",
    "# INICIO_RESPUESTA\n",
    "# Requisitos: Elabore una función que siempre devuelva True\n",
    "\n",
    "def mi_funcion() :\n",
    "    return True\n",
    "\n",
    "# FIN_RESPUESTA\n",
    "```\n",
    "\n",
    "## Esquema de la plantilla\n",
    "El esquema de la memoria deberá ser el siguiente:\n",
    "\n",
    "1. Explicar qué es una *DCGAN* y cómo funciona (haciendo énfasis en explicar las dos partes principales de este tipo de modelos) \n",
    "1. Describir brevemente el conjunto de datos inicial (*CIFAR10*)\n",
    "1. Entrenar una *DCGAN (Deep Convolutional Generative Adversarial Network)* para generar imágenes.\n",
    "1. Añadir *experience replay*\n",
    "1. Convertir la red a una *GAN condicional*\n",
    "\n",
    "En primer lugar vamos a cargar las librerías y funciones de apoyo que se van a utilizar en el código del cuadernillo. Si se quiere utilizar alguna librería adicional se puede añadir dicha librería en este punto o en la celda de código en la que se vaya a utilizar por primera vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710e9c4-a49d-4626-9055-69c2bb5ad996",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1710e9c4-a49d-4626-9055-69c2bb5ad996",
    "outputId": "1660d896-570c-488e-f8e7-d41f227fa7c4"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, BatchNormalization, Conv2DTranspose, LeakyReLU, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check for GPU\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcd39b-0270-402d-8e03-190f01de76c1",
   "metadata": {},
   "source": [
    "## Consideraciones iniciales\n",
    "\n",
    "Dado el tiempo de cómputo que exigen este tipo de redes se limitará el análisis de 50 epochs. Es muy recomendable, también que, si no se dispone de una tarjeta gráfica y una configuración compatible con tensorflow (puede comprobarse con la última salida del bloque anterior, si el número de GPUs disponible es 0) se utilice para la realización de esta práctica Google Colab. En este plataforma deberemos configurar el entorno de ejecución para que soporte GPUs, esto puede hacerse a través del menú *Entorno de ejecución* y la opción *Cambiar tipo de entorno de ejecución*, selecconando **GPU** como *Acelerador por hardware* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9n2L6NGH5m6Q",
   "metadata": {
    "id": "9n2L6NGH5m6Q"
   },
   "outputs": [],
   "source": [
    "# Definimos las constantes que utilizaremos a lo largo del cuadernillo\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88528613-6907-45ca-ad36-60c9658520dc",
   "metadata": {},
   "source": [
    "Es importante saber que para poder depurar algunos métodos como «fit» debemos cambiar el modo de ejecución. Para ello podemos dar el valor «True» al parámetro «run_eagerly» cuando compilemos el modelo. Cuidado, al cambiar este parámetro la ejecución del código será mucho más lenta. Para más información y consejos de depuración se recomienda utilizar los consejos que se indican en la propia página de Keras (https://keras.io/examples/keras_recipes/debugging_tips/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dae390-764d-4c9f-9950-e8ea75766eb5",
   "metadata": {
    "id": "72dae390-764d-4c9f-9950-e8ea75766eb5"
   },
   "source": [
    "## Memoria\n",
    "**Nombre:** <mark>Nombre</mark>\n",
    "\n",
    "**Correo UNED:** <mark>nombre@alumno.uned.es</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003dfc4-ba86-417d-b5f4-3f06c292512b",
   "metadata": {
    "id": "f003dfc4-ba86-417d-b5f4-3f06c292512b",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ¿Qué es una DCGAN?\n",
    "<mark>\\[Respuesta: Explicar lo que es una DCGAN, extensión aproximada de 2 párrafos (200 palabras) \\]</mark>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7bfec8-5f29-4fe5-9e92-c8a8a187b399",
   "metadata": {
    "id": "7b7bfec8-5f29-4fe5-9e92-c8a8a187b399",
    "tags": []
   },
   "source": [
    "### CIFAR10\n",
    "<mark>\\[Respuesta: Describir brevemente el conjunto de datos CIFAR10, puede utilizar celdas de código para apoyarse en la descripción\\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe33c5-e534-4b63-ae75-6cec51eac835",
   "metadata": {
    "id": "86fe33c5-e534-4b63-ae75-6cec51eac835"
   },
   "outputs": [],
   "source": [
    "# En primer lugar vamos a descargar el conjunto de datos\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4a96b-4fd0-438c-b3c1-2a14e32481c8",
   "metadata": {
    "id": "1ce4a96b-4fd0-438c-b3c1-2a14e32481c8"
   },
   "outputs": [],
   "source": [
    "# INICIO_RESPUESTA 0/7\n",
    "# Requisitos: De como valor de la variable «semilla_aleatoria» los últimos dos dígitos de su documento de identificación\n",
    "semilla_aleatoria = XX\n",
    "# FIN_RESPUESTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a20584-9a25-4826-b729-0857e19dc3d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "45a20584-9a25-4826-b729-0857e19dc3d7",
    "outputId": "455ec4cb-bb93-4df1-c7ec-f35087ef6bc5"
   },
   "outputs": [],
   "source": [
    "np.random.seed(semilla_aleatoria)\n",
    "tf.random.set_seed(semilla_aleatoria)\n",
    "\n",
    "# Vamos a visualizar un subconjunto de las imagenes que hemos cargado\n",
    "clases = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "plt.figure(figsize=(9.6,7.2))\n",
    "plt.suptitle(\"CIFAR-10\", size=18)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "pos = 1\n",
    "for n in np.random.randint(low=0,high=len(X_train),size=12):\n",
    "    plt.subplot(3, 4, pos)\n",
    "    plt.imshow(X_train[n])\n",
    "    plt.axis('off')\n",
    "    plt.title(clases[Y_train[n][0]], size=16)\n",
    "    pos += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974883a5-0036-45dd-9777-855c1ca9bda4",
   "metadata": {
    "id": "974883a5-0036-45dd-9777-855c1ca9bda4"
   },
   "source": [
    "### Pre-procesado de datos\n",
    "<mark>\\[Respuesta: Describir los pasos de preprocesado que se han realizado así como la justificación de los mismos (tener en cuenta que se utilizará la función de activación tangencial hipèrbólica)\\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e312deb-62a1-4fac-9fbb-234bbb4c2472",
   "metadata": {
    "id": "9e312deb-62a1-4fac-9fbb-234bbb4c2472"
   },
   "outputs": [],
   "source": [
    "# Dado que no tendremos una estructura de entrenamiento y validación, vamos a juntar todos las imágenes\n",
    "all_imgs = np.concatenate([X_train, X_test])\n",
    "all_labels = np.concatenate([Y_train, Y_test])\n",
    "\n",
    "# INICIO_RESPUESTA 1/7\n",
    "# Requisitos: Realice el pre-procesado de los datos de entrada teniendo en cuenta las recomendaciones que se indican en el capítulo 17 del libro, guarde el resultado en all_imgs.\n",
    "all_imgs = \n",
    "# FIN_RESPUESTA    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb4b49-58cd-42d0-8924-e080fec875ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24cb4b49-58cd-42d0-8924-e080fec875ed",
    "outputId": "b2dedc31-5b02-47e2-c465-c8401741fa70"
   },
   "outputs": [],
   "source": [
    "print(all_imgs.min())\n",
    "print(all_imgs.mean())\n",
    "print(all_imgs.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10f71a-cfc7-43e6-ade9-a6575728f5ef",
   "metadata": {
    "id": "5d10f71a-cfc7-43e6-ade9-a6575728f5ef"
   },
   "source": [
    "### DCGAN Inicial\n",
    "En este apartado se quiere crear una primera red usando la API secuencial de Keras.  Es importante en este punto revisar las recomendaciones que se presentan en el capítulo 17 del libro:\n",
    "\n",
    "<mark>\\[Respuesta: Describir las recomendaciones que se presentan en el capítulo 17 del libro. Si, tras la evaluación de estas recomendaciones se detectan inconsistencias o no se siguen todas, indicar por qué.\\]</mark>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67045816-214e-4a5e-a566-9c18a9101191",
   "metadata": {
    "id": "67045816-214e-4a5e-a566-9c18a9101191"
   },
   "source": [
    "#### Generador\n",
    "\n",
    "Para el generador se utilizará la siguiente estructura:\n",
    "\n",
    "1. Capa densa y reshape a 8 x 8 x 128 \n",
    "2. Capa de convolución transpuesta con 64 filtros (kernel de 4x4, 2 strides y padding 'same')\n",
    "3. Capa de convolución transpuesta con 64 filtros (kernel de 4x4, 2 strides y padding 'same')\n",
    "4. Capa convolucional con 3 filtros (kernel de 3x3, 1 stride, padding 'same' y función de activación 'tanh')\n",
    "\n",
    "Todas las capas convolucionales transpuestas tienen una función de activación Leaky ReLU (únicamente las transpuestas) y, tras cada capa se aplicará normalización por lotes (BatchNormalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2f8c9-88ec-41d1-aa1b-3eeb76592a88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ae2f8c9-88ec-41d1-aa1b-3eeb76592a88",
    "outputId": "b7f66039-421e-4d62-fe97-eab1844f3426"
   },
   "outputs": [],
   "source": [
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(100,)),  \n",
    "\n",
    "# INICIO_RESPUESTA 2/\n",
    "# Requisitos: Añada las capas indicadas para el generador      \n",
    "    \n",
    "# FIN_RESPUESTA \n",
    "])\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9df4c9-277d-43e9-bb8f-9e6fde7adb49",
   "metadata": {
    "id": "1a9df4c9-277d-43e9-bb8f-9e6fde7adb49"
   },
   "source": [
    "#### Discriminador\n",
    "\n",
    "Para el Discriminador se utilizará la siguiente estructura:\n",
    "\n",
    "1. Capa convolucional con 32 filtros (kernel de 4x4, 2 strides y padding 'same')\n",
    "2. Capa convolucional con 64 filtros (kernel de 4x4, 2 strides y padding 'same')\n",
    "3. Capa convolucioanl con 128 filtros (kernel de 4x4, 2 strides y padding 'same')\n",
    "4. Capa Densa con función de activación sigmoide\n",
    "\n",
    "Todas las capas convolucionales tienen una función de activación Leaky ReLU y, posteriormente se aplicarán normalización (BatchNormalization) y Dropout. Salvo la última capa convolucional que no aplicará normalización si no que aplanará el resultado de cara a la última capa densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc737cd-dc14-4c91-af3d-7189f3d36b8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecc737cd-dc14-4c91-af3d-7189f3d36b8f",
    "outputId": "52d111ae-4daf-43a0-8514-e9c7003dd579"
   },
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential([\n",
    "# INICIO_RESPUESTA 3/7\n",
    "# Requisitos: Añada las capas indicadas para el discriminador\n",
    "\n",
    "# FIN_RESPUESTA \n",
    "])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2e88a-2a5b-4f1b-9835-51e24f2353c7",
   "metadata": {
    "id": "09f2e88a-2a5b-4f1b-9835-51e24f2353c7"
   },
   "source": [
    "#### Modelo\n",
    "<mark>\\[Respuesta: Explicar los pasos de entrenamiento de una GAN, diferenciando el proceso de entrenamiento del generador y del discriminador. \\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27418c92-611e-422f-9b75-bfbbdb8d12fd",
   "metadata": {
    "id": "27418c92-611e-422f-9b75-bfbbdb8d12fd"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        \n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        \n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "    \n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=100, show_range=10, enable_show=True, enable_save=False):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.show_range = show_range\n",
    "        self.enable_show = enable_show\n",
    "        self.enable_save = enable_save\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if ((epoch+1) % self.show_range) == 0 or epoch == 0:\n",
    "          random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "          generated_images = self.model.generator(random_latent_vectors)\n",
    "          generated_images += 1\n",
    "          generated_images /= 2\n",
    "\n",
    "          generated_images.numpy()\n",
    "          plt.figure(figsize=(self.num_img, 1))\n",
    "          for i in range(self.num_img):\n",
    "              img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "              if self.enable_show:\n",
    "                plt.subplot(1, self.num_img, i + 1)\n",
    "                plt.imshow(img, cmap=\"binary\")\n",
    "                plt.axis(\"off\")\n",
    "              if self.enable_save:\n",
    "                img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n",
    "          if self.enable_show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NcE9Stky7Rg_",
   "metadata": {
    "id": "NcE9Stky7Rg_"
   },
   "outputs": [],
   "source": [
    "def plt_loss(history): \n",
    "    '''\n",
    "    Función que nos ayudará a visualizar la evolución de las pérdidas del generador y del discriminador\n",
    "    '''\n",
    "    f_num = \"{:.3f}\"\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.suptitle(\"Función de pérdida\", size=18)\n",
    "    plt.subplots_adjust(wspace=0.5, hspace = 0.5)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['d_loss'])\n",
    "    plt.title(\"Discriminador\")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['g_loss'])\n",
    "    plt.title(\"Generador\")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.tight_layout(pad=4)\n",
    "    plt.show()\n",
    "    print(f\"Pérdida discriminador: Min ({f_num.format(np.min(history.history['d_loss']))}) Max ({f_num.format(np.max(history.history['d_loss']))}) Media ({f_num.format(np.mean(history.history['d_loss']))})\")\n",
    "    print(f\"Pérdida generador: Min ({f_num.format(np.min(history.history['g_loss']))}) Max ({f_num.format(np.max(history.history['g_loss']))}) Media ({f_num.format(np.mean(history.history['g_loss']))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc703c-44e1-4ad1-995e-723a9fb24066",
   "metadata": {},
   "source": [
    "#### Optimizadores y función de pérdida\n",
    "<mark>\\[Respuesta: Explicar qué optimizadores se utilizarán para el discriminador y el generador y por qué. \\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TyCJvyVDOEfD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyCJvyVDOEfD",
    "outputId": "1d52ea25-b858-4d9a-d98c-571d48d929fb"
   },
   "outputs": [],
   "source": [
    "# INICIO_RESPUESTA 4/7\n",
    "# Requisitos: Inicialice los optimizadores que se utilizarán para el discriminador y para el generador, se aconseja utilizar valores LR de aproximadamente 0.0002\n",
    "d_optimizer = \n",
    "g_optimizer = \n",
    "# FIN_RESPUESTA \n",
    "\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iVupeg306ki1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVupeg306ki1",
    "outputId": "e4c88f68-e84d-4c93-8fc5-919084352c9b"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(all_imgs).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=d_optimizer,\n",
    "    g_optimizer=g_optimizer,\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "\n",
    "history = gan.fit(dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FBSbdPyM9Jct",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "FBSbdPyM9Jct",
    "outputId": "d31fcec3-f04e-4d88-dfaf-d09956d3d090"
   },
   "outputs": [],
   "source": [
    "plt_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WthOtggPEspl",
   "metadata": {
    "id": "WthOtggPEspl"
   },
   "source": [
    "#### Resultados\n",
    "<mark>\\[Respuesta: Explicar los resultados obtenidos visualizando la evolución de las pérdidas del discriminador y del generador. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iJ3rvsYqE6o4",
   "metadata": {
    "id": "iJ3rvsYqE6o4"
   },
   "source": [
    "### Experience replay\n",
    "<mark>\\[Respuesta: Explicar en qué consiste la técnica de *Experience replay* y qué resultados se esperan de su uso. \\]</mark>\n",
    "\n",
    "\n",
    "<mark>\\[Respuesta: Explicar qué estrategia de *Experience replay* (de las muchas posibles) se ha implementado en el modelo que hay a continuación. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a242-1703-4cd4-8d9c-9d88973f3dd3",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xNiBVfofE6NU",
   "metadata": {
    "id": "xNiBVfofE6NU"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.experience_replay = []\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        \n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        \n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # INICIO_RESPUESTA 5/7\n",
    "        # Requisitos: Implementar una estrategia de Experience replay a partir de un buffer de imágenes alamacenadas en cada iteración\n",
    "        \n",
    "        # FIN_RESPUESTA \n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KcO6ki8-FM7C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KcO6ki8-FM7C",
    "outputId": "0f9ce769-695a-42c7-83ee-c91058e4f26a"
   },
   "outputs": [],
   "source": [
    "gan_er = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan_er.compile(\n",
    "    d_optimizer=d_optimizer,\n",
    "    g_optimizer=g_optimizer,\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "\n",
    "history = gan_er.fit(dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R4qySJFTG-8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "R4qySJFTG-8d",
    "outputId": "2a0aa06c-77d3-488c-b8fb-d53ac883d229"
   },
   "outputs": [],
   "source": [
    "plt_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1-4BdOW5HCdr",
   "metadata": {
    "id": "1-4BdOW5HCdr"
   },
   "source": [
    "#### Resultados\n",
    "<mark>\\[Respuesta: Explicar los resultados obtenidos visualizando y compararlos con los obtenidos en la GAN sin *Experience replay*. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vr1I-B_6HPvA",
   "metadata": {
    "id": "Vr1I-B_6HPvA"
   },
   "source": [
    "### GAN condicional\n",
    "<mark>\\[Respuesta: Explicar en qué consisten las GAN condicionales y qué resultados se esperan de estos modelos en relación al modelo original y al modelo con *Experience replay*. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z10qhTbNHq-Z",
   "metadata": {
    "id": "Z10qhTbNHq-Z"
   },
   "source": [
    "#### Discriminador\n",
    "<mark>\\[Respuesta: Explicar las adaptaciones que necesitará el discriminador para realizar la discriminación basado en la clase. \\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EHyfA8dIxgvq",
   "metadata": {
    "id": "EHyfA8dIxgvq"
   },
   "outputs": [],
   "source": [
    "# INICIO_RESPUESTA 6/7\n",
    "# Requisitos: Implemente el discriminador para la GAN condicional, utilice la estructura del discriminador original y adáptela para que funcione con las etiquetas de clase\n",
    "#             (utilice la variable «discriminator» para almacenar el discriminador tal y como se hizo en el caso base)\n",
    "# Nota: se recomienda utilizar la API funcional para desarrollar este apartado.\n",
    "\n",
    "# FIN_RESPUESTA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3VB2Vp14KSm4",
   "metadata": {
    "id": "3VB2Vp14KSm4"
   },
   "source": [
    "#### Generador\n",
    "<mark>\\[Respuesta: Explicar las adaptaciones que necesitará el generador para generar imágenes de una clase determinada. \\]</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8s5eZ99-M8qf",
   "metadata": {
    "id": "8s5eZ99-M8qf"
   },
   "outputs": [],
   "source": [
    "# INICIO_RESPUESTA 7/7\n",
    "# Requisitos: Implemente el generador para la GAN condicional, utilice la estructura del generador original y adáptela para que funcione con las etiquetas de clase \n",
    "#             (utilice la variable «generator» para almacenar el generador tal y como se hizo en el caso base)\n",
    "# Nota: se recomienda utilizar la API funcional para desarrollar este apartado.\n",
    "\n",
    "# FIN_RESPUESTA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4dbd5b-21b8-4a21-8c43-8583d5dc6664",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ssxXbzZ-MWbU",
   "metadata": {
    "id": "ssxXbzZ-MWbU"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.experience_replay = []\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images[0])[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        generated_images = self.generator([real_images[1],random_latent_vectors])\n",
    "\n",
    "        combined_images = tf.concat([generated_images, real_images[0]], axis=0)\n",
    "\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        combined_labels = tf.concat([real_images[1], real_images[1]], axis=0)\n",
    "\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator([combined_images, combined_labels])\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator([self.generator([real_images[1],random_latent_vectors]), real_images[1]])\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "    \n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, y_train_enc = None, num_img=3, latent_dim=100, show_range=10,\n",
    "                 enable_show=True, enable_save=False,\n",
    "                 batch_size = 128):\n",
    "        super().__init__()\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.show_range = show_range\n",
    "        self.enable_show = enable_show\n",
    "        self.enable_save = enable_save\n",
    "        self.batch_size = batch_size\n",
    "        self.y_train_enc = y_train_enc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if ((epoch+1) % self.show_range) == 0 or epoch == 0:\n",
    "          random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "          labels = self.y_train_enc[epoch:epoch+self.num_img]\n",
    "          generated_images = self.model.generator([labels,random_latent_vectors])\n",
    "          generated_images = (generated_images + 1) / 2.0\n",
    "          \n",
    "          generated_images.numpy()\n",
    "          plt.figure(figsize=(self.num_img, 1))\n",
    "          for i in range(self.num_img):\n",
    "              img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "              if self.enable_show:\n",
    "                plt.subplot(1, self.num_img, i + 1)\n",
    "                plt.imshow(img, cmap=\"binary\")\n",
    "                plt.axis(\"off\")\n",
    "              if self.enable_save:\n",
    "                img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n",
    "          if self.enable_show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G-mqO56yMdlL",
   "metadata": {
    "id": "G-mqO56yMdlL"
   },
   "outputs": [],
   "source": [
    "# Dado que ahora el generador y el discriminador utilizarán la clase de cada elemento, es necesario utilizar las etiquetas, transformándolas previamente a un array\n",
    "all_labels_enc = keras.utils.to_categorical(all_labels, 10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_imgs, all_labels_enc)).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egUt_DBRMgrW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "egUt_DBRMgrW",
    "outputId": "58e5a940-01ae-45b1-c1ab-e7690e5c0705"
   },
   "outputs": [],
   "source": [
    "conditional_gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "conditional_gan.compile(\n",
    "    d_optimizer=d_optimizer,\n",
    "    g_optimizer=g_optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "history = conditional_gan.fit(dataset, epochs=epochs, callbacks=[GANMonitor(all_labels_enc,\n",
    "                                                                num_img=10,\n",
    "                                                                latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rBORlL57RcRL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "rBORlL57RcRL",
    "outputId": "f904fe93-440a-48b1-cf5e-337a0b2ae27c"
   },
   "outputs": [],
   "source": [
    "plt_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc550047-90c9-43a8-ba46-1ba0f1762b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_labels = keras.utils.to_categorical([x for x in range(10)] * 4, 10)\n",
    "\n",
    "random_latent_vectors = tf.random.normal(shape=(len(classes_labels), latent_dim))\n",
    "generated_images = conditional_gan.generator([classes_labels,random_latent_vectors])\n",
    "generated_images = (generated_images + 1) / 2.0\n",
    "# generated_images.numpy()\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "pos = 1\n",
    "classes_to_int = np.argmax(classes_labels, axis=-1)\n",
    "for n in range(generated_images.shape[0]):\n",
    "    plt.subplot(4, 10, pos)\n",
    "    img = keras.preprocessing.image.array_to_img(generated_images[n])\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(clases[classes_to_int[n]], size=12)\n",
    "    pos += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1429a69-e8e8-4179-acbd-dfc34ca4fbc3",
   "metadata": {},
   "source": [
    "#### Resultados\n",
    "<mark>\\[Respuesta: Explicar los resultados obtenidos visualizando y compararlos con los obtenidos en la GAN que se ha utilizado como base y la GAN con *Experience replay*. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f996b-440e-4db5-85ec-fc8cdc6f0048",
   "metadata": {},
   "source": [
    "### Conclusiones finales\n",
    "<mark>\\[Respuesta: Resumir el trabajo realizado y las conclusiones principales que se extraen del mismo. \\]</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8641815-2def-4376-bd06-0439ca14c7d1",
   "metadata": {},
   "source": [
    "### (Opcional) Cycle-GANs \n",
    "<mark>\\[Respuesta: Buscar información de las *Cycle GANs* y resumir su funcionamiento, haciendo especial énfasis en las novedades que introducen sobre las tipologías vistas en esta práctica . \\]</mark>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PlantillaGANs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
