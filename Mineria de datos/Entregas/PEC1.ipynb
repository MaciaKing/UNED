{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breve resumen Teorico del problema\n",
    "El problema de la replicabilidad en la actualidad representa un desafío significativo, especialmente en el campo del machine learning, donde la variedad de modelos desarrollados es amplia y diversa. \n",
    "\n",
    "La existencia de múltiples modelos para resolver un mismo problema genera dificultades al intentar replicar los resultados, lo que afecta la validación y confiabilidad de los experimentos. Este tema es abordado de manera destacada en el artículo \"Estimating Replicability of Classifier Learning Experiments\", que analiza los retos y las estrategias para evaluar la consistencia y reproducibilidad de los experimentos en el aprendizaje de clasificadores. \n",
    "\n",
    "Existen varios factores específicos que complican la replicabilidad, como los conjuntos de datos sesgados, la variabilidad en la selección de hiperparámetros y las diferencias en el entorno de ejecución, incluyendo hardware, software y versiones de librerías. Para mitigar este problema, es fundamental establecer prácticas estandarizadas.\n",
    "\n",
    "La prueba t de Student es un análisis estadístico paramétrico que requiere que los datos analizados cumplan ciertas condiciones: deben ser variables de intervalos o razones y seguir una distribución normal. Además, las variables comparadas deben ser independientes entre sí. Por ejemplo, al medir niveles de depresión en grupos de hombres y mujeres o al comparar personas casadas con solteras, es fundamental que estas variables no estén relacionadas para asegurar resultados válidos en el análisis. \n",
    "\n",
    "Es importante señalar que existen diferentes versiones de la prueba t, como la prueba t para muestras independientes, la prueba t para muestras relacionadas (o emparejadas) y la prueba t para una sola muestra, dependiendo del tipo de comparación que se realice. La prueba también asume homogeneidad de varianza entre los grupos; si esta condición no se cumple, la prueba t de Welch puede ser más apropiada. \n",
    "\n",
    "Aunque la normalidad de los datos es una suposición clave, la prueba t puede ser relativamente robusta a pequeñas desviaciones, especialmente con muestras grandes. Asimismo, es útil considerar el cálculo del tamaño del efecto para evaluar la magnitud de la diferencia entre grupos, más allá de su significancia estadística.\n",
    "\n",
    "Para esta practica voy a utilizar la técnica de 5x2 cross-validation porque se ha demostrado que es especialmente efectiva para evaluar la replicabilidad de los experimentos en modelos de clasificación. Según Bouckaert (2004), esta metodología permite obtener estimaciones más robustas y confiables del rendimiento del modelo, al dividir los datos en dos subconjuntos en cada iteración y realizar varias repeticiones. Esto ayuda a reducir el sesgo y la variabilidad que podrían influir en los resultados de los modelos.\n",
    "\n",
    "Además, la validación cruzada 5x2 es considerada una de las mejores técnicas para garantizar una evaluación justa y equilibrada, asegurando que los modelos sean probados de manera consistente y sin sobreajuste. Esta técnica es particularmente útil para medir la replicabilidad de los modelos, lo que la convierte en una opción ideal para este análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen de las técnicas\n",
    "Para esta práctica, se propone desarrollar dos clasificadores y comparar sus métricas de rendimiento utilizando la prueba t de Student y el test de McNemar.\n",
    "\n",
    "Para garantizar la replicabilidad en esta práctica, hemos concluido que la mejor opción es utilizar la validación 5x2. Por lo tanto, para entrenar los dos modelos correspondientes, aplicaremos este método de validación en ambos casos.\n",
    "## Técnica: Test de McNeamar\n",
    "\n",
    "### ¿Cómo se realiza? \n",
    "El test de McNemar es una prueba estadística utilizada para comparar dos proporciones en datos emparejados, especialmente cuando se tiene información categórica con dos posibles resultados. Se emplea cuando se quiere evaluar si hay cambios significativos en las respuestas de los participantes antes y después de una intervención o entre dos condiciones de un mismo grupo. Para llevarlo a cabo, se utiliza una tabla de contingencia 2x2 con las siguientes categorías:\n",
    "\n",
    "- A1B1: Casos en los que ambos grupos tienen la misma respuesta (antes y después o en ambas condiciones).\n",
    "- A1B2: Casos en los que el grupo tenía una respuesta en el primer momento y otra diferente en el segundo.\n",
    "- A2B1: Casos en los que el grupo tenía una respuesta diferente al principio y la misma al final.\n",
    "- A2B2: Casos donde ambos grupos tienen respuestas diferentes.\n",
    "\n",
    "El test se basa en la diferencia entre los casos A1B2 y A2B1, comparando el número de cambios en una dirección con el número de cambios en la otra dirección. La fórmula para calcular el estadístico  $ X^{2} $  es: $ X^{2} = \\frac{(b-c)^{2}}{{b+c}}$, donde b y c son los valores de las categorías A1B2 y A2B1, respectivamente.\n",
    "\n",
    "### ¿En qué está basado? \n",
    "El test de McNemar se basa en una distribución binomial y en la hipótesis de que, si no existe un cambio significativo entre las dos mediciones o condiciones, los cambios de categoría (de A1 a A2 o de B1 a B2) deben ser aproximadamente simétricos. Esta prueba es especialmente útil en estudios de medidas repetidas, como en investigaciones psicológicas, clínicas y de salud, donde se mide la misma variable en dos momentos diferentes o bajo dos condiciones distintas.\n",
    "\n",
    "### Puntos fuertes:\n",
    "- Simplicidad y aplicación directa: Es fácil de implementar cuando se tienen datos categóricos emparejados.\n",
    "- Adecuado para datos pequeños: Funciona bien incluso con muestras pequeñas, a diferencia de otras pruebas estadísticas.\n",
    "- Control de sesgo de selección: Al comparar resultados de la misma unidad de observación en dos momentos o condiciones, minimiza posibles sesgos.\n",
    "\n",
    "### Puntos débiles:\n",
    "- Restricciones en la estructura de los datos: Solo se utiliza con datos dicotómicos (dos categorías) y con muestras emparejadas.\n",
    "- Sensibilidad limitada: No es adecuado para situaciones con muchas respuestas neutrales o indeterminadas, ya que solo se enfoca en los cambios significativos entre las categorías.\n",
    "- Requiere un número adecuado de cambios: Si las diferencias entre las categorías son muy pequeñas (es decir, pocos casos en A1B2 y A2B1), los resultados pueden no ser significativos.\n",
    "\n",
    "## Técnica: Test de t de Student\n",
    "### ¿Cómo se realiza? \n",
    "El test t de Student es una prueba estadística que se utiliza para comparar las medias de dos grupos y determinar si existe una diferencia significativa entre ellas. Existen dos versiones del test t:\n",
    "- Test t para muestras independientes: Compara las medias de dos grupos independientes entre sí.\n",
    "- Test t para muestras relacionadas (o apareadas): Compara las medias de dos grupos relacionados, como las mediciones de un mismo grupo antes y después de una intervención.\n",
    "La fórmula básica para calcular el estadístico t es:\n",
    "\n",
    "$  t = \\frac{\\overline{X_{1}} - \\overline{X_2}}{\\sqrt{\\frac{s_{1}^{2}}{n_1} + \\frac{s_{2}^2}{n_2}}} $\n",
    "\n",
    "donde:\n",
    "- $ \\overline{X_1} $ y $ \\overline{X_1} $ son las medias de los dos grupos.\n",
    "- $ s_{1}^{2} $ y $ s_{2}^{2} $ son las varianzas de los dos grupos.\n",
    "- $ n_1 $ y $ n_2 $ son los tamaños de las muestras.\n",
    "\n",
    "\n",
    "El valor de t se compara con una distribución t de Student para determinar la significancia de la diferencia entre las medias.\n",
    "\n",
    "### ¿En qué está basado?\n",
    "El test t de Student se basa en la teoría de la estimación de la media de una población a partir de una muestra. Asume que los datos siguen una distribución normal y que las varianzas de las dos poblaciones que se comparan son iguales (en el caso del test t para muestras independientes). Este test se utiliza en contextos donde las muestras son relativamente pequeñas y la distribución normal de los datos se asume o se puede verificar.\n",
    "\n",
    "### Puntos fuertes\n",
    "- Facilidad de aplicación: Es ampliamente utilizado en muchos campos de investigación debido a su simplicidad y fiabilidad para comparar dos medias.\n",
    "- Versatilidad: Puede aplicarse tanto a muestras independientes como relacionadas.\n",
    "- Eficiencia con muestras pequeñas: A diferencia de otros test estadísticos, el test t es útil incluso cuando las muestras son pequeñas, siempre que se cumplan las suposiciones de normalidad.\n",
    "\n",
    "### Puntos débiles\n",
    "- Asume normalidad: Requiere que los datos se distribuyan de manera aproximadamente normal. Si los datos no cumplen esta suposición, los resultados pueden ser sesgados.\n",
    "- Sensibilidad a varianzas desiguales: En el caso de muestras independientes, si las varianzas de los grupos no son iguales, el test puede ser inapropiado o menos preciso, aunque existen ajustes (como el test t de Welch).\n",
    "- No adecuado para muestras grandes con varianzas desconocidas: En casos de muestras grandes, otros test como el análisis de varianza (ANOVA) podrían ser más apropiados si se comparan más de dos grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necesarios del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del dataset\n",
    "En este proyecto, uno de los elementos clave es seleccionar un dataset adecuado para entrenar y evaluar nuestro modelo de machine learning. En particular, necesitamos un conjunto de datos que cumpla con ciertos requisitos específicos para aplicar el test t de Student, el test de McNemar y 5x2 crossvalidation.\n",
    "\n",
    "Requisitos del Dataset\n",
    "- Número de Instancias: Debido a que vamos a utilizar la técnica de validación cruzada 5X2 (5-fold cross-validation con 2 repeticiones), es fundamental contar con un dataset que tenga una cantidad significativa de instancias. Este tipo de validación cruzada implica dividir el dataset en 5 subconjuntos (folds) y realizar 2 repeticiones del proceso.\n",
    "\n",
    "- Variables Categóricas: Para este ejercicio, necesitamos un modelo que prediga una variable categórica. Esto es necesario porque las métricas de evaluación, como el test t de Student y el test de McNemar, se aplican específicamente a este tipo de variables\n",
    "\n",
    "El conjunto de datos elegido para esta práctica es el conocido [\"Adult Income Dataset\"](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset) (también llamado \"Census Income Dataset\"). El objetivo de este dataset es predecir si una persona gana más de 50,000 dólares anuales o no, basándose en variables como la edad, el nivel educativo, la ocupación, el estado civil, el número de horas trabajadas por semana, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../Datasets/adult.csv') # https://www.kaggle.com/datasets/wenruliu/adult-income-dataset\n",
    "df = df_all.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario convertir todos los datos de tipo \"object\" a enteros, ya que estos son variables categóricas con valores específicos asignados. Para que el modelo pueda procesar correctamente estos datos, primero los transformaremos a un formato categórico, asignando un código único a cada categoría. Luego, convertiremos estas variables categóricas a valores enteros, lo que permitirá que el modelo pueda evaluarlas y utilizarlas en el entrenamiento. Esta transformación es esencial para que los modelos puedan interpretar las relaciones entre las distintas categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   age              48842 non-null  int64\n",
      " 1   workclass        48842 non-null  int8 \n",
      " 2   fnlwgt           48842 non-null  int64\n",
      " 3   education        48842 non-null  int8 \n",
      " 4   educational-num  48842 non-null  int64\n",
      " 5   marital-status   48842 non-null  int8 \n",
      " 6   occupation       48842 non-null  int8 \n",
      " 7   relationship     48842 non-null  int8 \n",
      " 8   race             48842 non-null  int8 \n",
      " 9   gender           48842 non-null  int8 \n",
      " 10  capital-gain     48842 non-null  int64\n",
      " 11  capital-loss     48842 non-null  int64\n",
      " 12  hours-per-week   48842 non-null  int64\n",
      " 13  native-country   48842 non-null  int8 \n",
      " 14  income           48842 non-null  int8 \n",
      "dtypes: int64(6), int8(9)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['workclass', 'education', 'marital-status','occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "# Convertir las columnas de object a categóricas\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')  # Convertir a categórico\n",
    "\n",
    "# Convertir categorías a enteros\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].cat.codes  # Convertir a códigos numéricos\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, debemos dividir los datos en dos conjuntos, X (características) e Y (etiquetas). Luego, solo escalaremos el vector X, ya que escalar Y no tiene sentido, dado que representa las etiquetas o valores objetivo que no requieren normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39073, 14)\n",
      "(39073,)\n",
      "-\n",
      "(9769, 14)\n",
      "(9769,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values  # Todas las columnas excepto la última\n",
    "y = df.iloc[:, -1].values   # Solo la última columna\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características (X)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('-')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los Modelos y Entrenamiento\n",
    "A continuación, se crearán un modelo SVM y un modelo de regresión logística, los cuales se entrenarán de manera equitativa para asegurar la validez de los test posteriores.\n",
    "\n",
    "En cada iteración, se separan los datos y los modelos de forma independiente para garantizar una evaluación justa. Este procedimiento sigue una validación cruzada 5x2, en la que los datos se dividen en dos subconjuntos en 5 repeticiones, lo que permite evaluar el rendimiento de los modelos de manera robusta y sin sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados 5x2 Cross-Validation:\n",
      "[Logistic Regression] Promedio de Accuracy: 0.8242162239295885\n",
      "****\n",
      "[SVM] Promedio de Accuracy: 0.8396693667765863\n"
     ]
    }
   ],
   "source": [
    "# Configuración de 5x2 Cross-Validation\n",
    "kf = RepeatedKFold(n_splits=2, n_repeats=5, random_state=42)\n",
    "\n",
    "# Modelos\n",
    "logistic_model = LogisticRegression()\n",
    "svm_model = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Almacenar los resultados de cada iteración\n",
    "logistic_scores = []\n",
    "svm_scores = []\n",
    "\n",
    "# 5x2 Cross-Validation\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # Entrenar y evaluar Logistic Regression\n",
    "    logistic_model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_logistic = logistic_model.predict(X_test_cv)\n",
    "    logistic_scores.append(accuracy_score(y_test_cv, y_pred_logistic))\n",
    "    \n",
    "    # Entrenar y evaluar SVM\n",
    "    svm_model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_svm = svm_model.predict(X_test_cv)\n",
    "    svm_scores.append(accuracy_score(y_test_cv, y_pred_svm))\n",
    "\n",
    "# Promedios finales\n",
    "print(\"\\nResultados 5x2 Cross-Validation:\")\n",
    "print(\"[Logistic Regression] Promedio de Accuracy:\", np.mean(logistic_scores))\n",
    "print(\"****\")\n",
    "print(\"[SVM] Promedio de Accuracy:\", np.mean(svm_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de student\n",
    "- H₀: La media de los puntajes de validación cruzada de la regresión logística es igual a la media de los puntajes del SVM.\n",
    "- H₁: La media de los puntajes de validación cruzada de la regresión logística es diferente de la media de los puntajes del SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test de Student:\n",
      "T-statistic: -10.929903029186752\n",
      "P-value: 2.23521428493525e-09\n",
      "Hay diferencias significativas entre los modelos.\n"
     ]
    }
   ],
   "source": [
    "# Test de Student\n",
    "t_stat, p_value = ttest_ind(logistic_scores, svm_scores)\n",
    "\n",
    "print(\"\\nTest de Student:\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Hay diferencias significativas entre los modelos.\")\n",
    "else:\n",
    "    print(\"No hay diferencias significativas entre los modelos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido un p-value muy pequeño, lo que indica que existe una diferencia significativa entre los modelos entrenados. Con este resultado, podemos rechazar la hipótesis nula (H₀), ya que sugiere que, en cada fase de entrenamiento, los resultados obtenidos para los dos modelos fueron consistentemente diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] Scores: [0.8229001381993141, 0.8268325143325144, 0.8205968162972821, 0.8283681408681409, 0.8271484874852844, 0.8210995085995086, 0.8214157751957823, 0.8266277641277642, 0.8264318984490966, 0.8207411957411958]\n",
      "[SVM] Scores: [0.8371807339919127, 0.8424447174447175, 0.8344679326406306, 0.8438779688779688, 0.8415826380713518, 0.8377354627354627, 0.8368736244049751, 0.8423423423423423, 0.8424015969698521, 0.8377866502866503]\n"
     ]
    }
   ],
   "source": [
    "print(\"[Logistic Regression] Scores:\", logistic_scores)\n",
    "print(\"[SVM] Scores:\", svm_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, podemos observar que en cada iteración, ninguno de los valores coincide. Aunque los valores se acercan entre sí, no llegan a ser idénticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de McNemar\n",
    "A continuación, vamos a comparar las predicciones de ambos modelos con los valores de prueba (y_test) y construir una tabla de contingencia para analizar las coincidencias y diferencias entre ellos. Los valores n11, n10, n01 y n00 reflejan las distintas combinaciones de aciertos y fallos de los dos modelos.\n",
    "\n",
    "Las hipótesis que se plantean son las siguientes:\n",
    "\n",
    "- H₀: La cantidad de casos en los que los modelos difieren en su clasificación (uno acierta y el otro falla) es igual. Es decir, no hay diferencia significativa en los errores cometidos por los dos modelos.\n",
    "- H₁: La cantidad de casos en los que los modelos difieren en su clasificación (uno acierta y el otro falla) no es igual. Es decir, existe una diferencia significativa en los errores cometidos por los dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test de McNemar:\n",
      "Estadístico Chi2: 219.0\n",
      "P-value: 2.4537591789347086e-13\n",
      "Hay diferencias significativas entre los modelos.\n"
     ]
    }
   ],
   "source": [
    "# Genera predicciones\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Construimos la tabla de contingencia comparando las predicciones de ambos modelos con los valores reales\n",
    "# n11: Número de veces que ambos modelos acertaron en la clasificación\n",
    "n11 = sum((y_pred_logistic == y_test) & (y_pred_svm == y_test))\n",
    "# n10: Número de veces que el modelo de regresión logística acertó y el modelo SVM falló\n",
    "n10 = sum((y_pred_logistic == y_test) & (y_pred_svm != y_test))\n",
    "# n01: Número de veces que el modelo de regresión logística falló y el modelo SVM acertó\n",
    "n01 = sum((y_pred_logistic != y_test) & (y_pred_svm == y_test))\n",
    "# n00: Número de veces que ambos modelos fallaron en la clasificación\n",
    "n00 = sum((y_pred_logistic != y_test) & (y_pred_svm != y_test))\n",
    "\n",
    "# Aplicamos el test de McNemar\n",
    "mcnemar_result = mcnemar([[n11, n10], [n01, n00]])\n",
    "\n",
    "print(\"\\nTest de McNemar:\")\n",
    "print(f\"Estadístico Chi2: {mcnemar_result.statistic}\")\n",
    "print(f\"P-value: {mcnemar_result.pvalue}\")\n",
    "\n",
    "if mcnemar_result.pvalue < 0.05:\n",
    "    print(\"Hay diferencias significativas entre los modelos.\")\n",
    "else:\n",
    "    print(\"No hay diferencias significativas entre los modelos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor $ P_{value}=2.45×10^{−13}$ es extremadamente pequeño, mucho menor que el umbral de significancia comúnmente utilizado de 0.05. Esto nos permite rechazar la hipótesis nula (H₀), que establece que no hay diferencias significativas entre los modelos en cuanto a los errores de clasificación.\n",
    "\n",
    "Dado que el estadístico Chi2 es bastante alto y el valor p es muy bajo, podemos concluir que hay una diferencia estadísticamente significativa entre los modelos evaluados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
